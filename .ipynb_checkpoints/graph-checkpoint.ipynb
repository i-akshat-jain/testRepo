{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ab127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9235d91-a68e-4e4a-8fe6-f08100d0fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x00000203b061c728>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import mplcursors\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce8e1a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asceding\n"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 93 fields in line 10131, saw 95\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     data_frames[variable_name] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Try a different encoding if 'utf-8' fails\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:889\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1034\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1095\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1238\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1251\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1499\u001b[0m, in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x9c in position 0: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Try a different encoding if 'utf-8' fails\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m         data_frames[variable_name] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatin1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError reading file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: Unable to decode using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1700\u001b[0m     (\n\u001b[0;32m   1701\u001b[0m         index,\n\u001b[0;32m   1702\u001b[0m         columns,\n\u001b[0;32m   1703\u001b[0m         col_dict,\n\u001b[1;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 93 fields in line 10131, saw 95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the folder containing the files\n",
    "folder_path = 'NormalvsTumor_HILIC_ALL/'\n",
    "\n",
    "# List all files in the folder\n",
    "file_names = os.listdir(folder_path)\n",
    "\n",
    "# Create a dictionary to store DataFrames with variable names\n",
    "data_frames = {}\n",
    "\n",
    "# Loop through the files and read them into pandas DataFrames\n",
    "for file_name in file_names:\n",
    "    # Assuming your files are CSV, modify the extension accordingly if needed\n",
    "    if file_name.endswith('.csv'):\n",
    "        # Remove the extension to create a variable name\n",
    "        variable_name = os.path.splitext(file_name)[0]\n",
    "        # Remove specified prefixes and suffixes from the variable name\n",
    "        variable_name = variable_name.replace('CRC_HILIC_', '').replace('_Ttest', '')\n",
    "        \n",
    "        print(variable_name)\n",
    "\n",
    "        # Read the file into a DataFrame and store it in the dictionary\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            data_frames[variable_name] = pd.read_csv(file_path, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            # Try a different encoding if 'utf-8' fails\n",
    "            try:\n",
    "                data_frames[variable_name] = pd.read_csv(file_path, encoding='latin1')\n",
    "            except UnicodeDecodeError:\n",
    "                print(f\"Error reading file '{file_name}': Unable to decode using 'utf-8' or 'latin1'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeea8122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f2a8a-4cb5-4dfd-9ddd-8ddf008c1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "results_dict = {}\n",
    "selected_mz_value = 694.31494\n",
    "# Iterate through the DataFrames\n",
    "for variable_name, df in data_frames.items():\n",
    "    # Check if the variable name contains 'output'\n",
    "    if 'output' in variable_name:\n",
    "        # Assuming 'mz' is a column in the DataFrame\n",
    "        selected_row_output = df[df['mz'] == selected_mz_value]\n",
    "\n",
    "        if not selected_row_output.empty:\n",
    "            raw_pval = selected_row_output['raw_pval'].values[0]\n",
    "            q_fdr = selected_row_output['q_fdr'].values[0]\n",
    "            log_fc_matched = selected_row_output['log_fc_matched'].values[0]\n",
    "            log_fc_matched = float(log_fc_matched)\n",
    "            q_fdr = float(q_fdr)\n",
    "\n",
    "            # Check q_fdr and assign stars accordingly\n",
    "            if q_fdr < 0.05 and q_fdr > 0.01:\n",
    "                q_fdr_stars = '*'\n",
    "            elif q_fdr < 0.01 and q_fdr > 0.001:\n",
    "                q_fdr_stars = '**'\n",
    "            elif q_fdr < 0.001:\n",
    "                q_fdr_stars = '***'\n",
    "            # Save the results in the dictionary\n",
    "            results_dict[variable_name] = {\n",
    "                'raw_pval': raw_pval,\n",
    "                'q_fdr': q_fdr,\n",
    "                'log_fc_matched': log_fc_matched,\n",
    "                'q_fdr_stars': q_fdr_stars\n",
    "            }\n",
    "        else:\n",
    "            print(f\"No data found for the selected 'mz' value in DataFrame '{variable_name}'.\")\n",
    "            \n",
    "for variable_name, results in results_dict.items():\n",
    "    print(f\"\\nResults for DataFrame '{variable_name}':\")\n",
    "    print(f\"Raw P-value: {results['raw_pval']}\")\n",
    "    print(f\"Q FDR: {results['q_fdr']}\")\n",
    "    print(f\"Log FC Matched: {results['log_fc_matched']}\")\n",
    "    print(f\"Q FDR Stars: {results['q_fdr_stars']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5c135-4ac1-4ea8-b71e-4dd5a0659d18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for variable_name, df in data_frames.items():\n",
    "    # Check if the variable name contains 'output'\n",
    "    # Extract results from the dictionary\n",
    "    if variable_name in results_dict:\n",
    "        q_fdr_stars = results_dict[variable_name]['q_fdr_stars']\n",
    "        # Ensure that log_fc_matched is a float or set it to 'N/A' otherwise\n",
    "        try:\n",
    "            log_fc_matched = float(results_dict[variable_name]['log_fc_matched'])\n",
    "        except ValueError:\n",
    "            log_fc_matched = \"N/A\"\n",
    "\n",
    "\n",
    "    # Plot diagrams only for DataFrames without 'output' in their names\n",
    "    if 'output' not in variable_name:\n",
    "        # Use the existing code to create the boxplot and swarmplot\n",
    "\n",
    "        desired_row_index = df.index[df['mz'] == selected_mz_value].tolist()\n",
    "\n",
    "        if len(desired_row_index) == 1:\n",
    "            desired_row_index = desired_row_index[0] + 1\n",
    "\n",
    "            row_data = df.iloc[desired_row_index - 1]\n",
    "            case_columns = row_data.filter(like='_Case').tolist()\n",
    "            control_columns = row_data.filter(like='_Control').tolist()\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(3, 4))\n",
    "\n",
    "            ax.scatter([1] * len(case_columns), case_columns, color=\"red\", label=\"Tumor\", s=3)\n",
    "            ax.scatter([2] * len(control_columns), control_columns, color=\"green\", label=\"Normal\", s=3)\n",
    "\n",
    "            ax.boxplot([case_columns, control_columns], labels=['Tumor', 'Normal'], patch_artist=True,\n",
    "                       boxprops=dict(facecolor='white', alpha=0.5, color='black', linewidth=1),\n",
    "                       medianprops=dict(color='black'), showfliers=False)\n",
    "\n",
    "            ax.set_xticklabels(['Tumor', 'Normal'], rotation=90)\n",
    "            ax.set_xlabel(variable_name, fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Relative Abundance')\n",
    "            ax.set_title(f'm/z={selected_mz_value:.4f}', fontsize=12, fontweight='bold')\n",
    "\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Case'),\n",
    "                Line2D([0], [0], marker='o', color='w', markerfacecolor='green', markersize=10, label='Control'),\n",
    "            ]\n",
    "\n",
    "            ax.text(1.01, 0.94, f'q:{q_fdr_stars}\\nLogFC:{log_fc_matched:.2f}', verticalalignment='center', horizontalalignment='left',\n",
    "                    transform=ax.transAxes, color='black', fontsize=8)\n",
    "\n",
    "            plt.tight_layout()\n",
    "             # Add mplcursors annotation\n",
    "            mplcursors.cursor(hover=True)\n",
    "            plt.savefig(f'boxplot_swarmplot_{variable_name}.png', dpi=500, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            print(f\"Plot done for DataFrame '{variable_name}'\")\n",
    "\n",
    "        else:\n",
    "            print(f\"No unique row found for the selected 'mz' value in DataFrame '{variable_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5d007-d77a-4fb4-9acc-c16b876b4297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87842cf-8571-494a-aaeb-316a9e9951e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b3874-3e76-490c-bd9c-3ac1f76da16d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
